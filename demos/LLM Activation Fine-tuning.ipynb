{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pretty-diagram",
   "metadata": {},
   "source": [
    "# LLM Activation Fine-Tuning Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Deps\n",
    "from IPython.lib.pretty import pretty\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-builder",
   "metadata": {},
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "In this demo, we will explore an **experimental** workflow for fine-tuning models on top of activations retreived from foundational models hosted on the Vector cluster. We will briefly demonstrate the a few fundamental concepts in the following sections:\n",
    "\n",
    "* Text generation\n",
    "* Model querying and activation generation\n",
    "* Fine-tuning\n",
    "\n",
    "We will be interfacing with a deployment of the Open Pre-trained Transformers (OPT). This demonstration will utilize the small OPT-125M parameter model for simplicity, however, the workflow remains the same when querying larger models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-macro",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "\n",
    "The Vector OPT Client class will be our primary tool for querying the OPT deployment. The OPT deployment exposes a RESTful API which is conveniently wrapped by the Client. \n",
    "\n",
    "### Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_HOST = \"172.17.8.104\"\n",
    "OPT_PORT = \"6969\"\n",
    "\n",
    "client = Client(host=OPT_HOST, port=OPT_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-fashion",
   "metadata": {},
   "source": [
    "The client provides a set of functions for interacting with the remote model. For example, we can use the ``generate`` function to perform text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello World\"\n",
    "response = client.generate(prompt)\n",
    "\n",
    "print(\"Prompt: \", prompt)\n",
    "print(\"Generation: \", response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-carry",
   "metadata": {},
   "source": [
    "We can also pass in an array of prompts and adjust hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Hello World\",\n",
    "    \"Fizz Buzz\"\n",
    "]\n",
    "\n",
    "response = client.generate(prompts, temperature=0.8)\n",
    "\n",
    "\n",
    "for prompt, generation in zip(prompts, response['choices']):\n",
    "    print(\"Prompt: \", prompt)\n",
    "    print(\"Generation: \", generation['text'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-alexandria",
   "metadata": {},
   "source": [
    "## Activation Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-bishop",
   "metadata": {},
   "source": [
    "Activation generation is also quite easy. We can use the client to query the remote model and explore the various modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.module_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-chick",
   "metadata": {},
   "source": [
    "We can select the module names of interest and pass them into a ``get_activations`` function alongside our set of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_names = ['decoder.layers.11.fc2']\n",
    "\n",
    "response = client.get_activations(prompts, module_names)\n",
    "\n",
    "pprint(response)\n",
    "print(\"Tensor Shape:\", response[0]['decoder.layers.11.fc2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-microphone",
   "metadata": {},
   "source": [
    "### IMDB Sentiment Classification Dataset\n",
    "\n",
    "For a set of prompts, we can use the ``get_activations`` function to generate a set of activations that can be cached for offline use. Let's now take a look at how to do this using the [IMDB Sentiment Analysis Dataset](https://huggingface.co/datasets/imdb).\n",
    "\n",
    "The dataset consists of 25,000 highly polar movie reviews for training, and another 25,000 for testing. The task is binary sentiment classification, where labels indicate either a positive or negative review.\n",
    "\n",
    "Sample Review:\n",
    "> \"This movie sucked. It really was a waste of my life. The acting was atrocious, the plot completely implausible. Long, long story short, these people get \"terrorized\" by this pathetic \"crazed killer\", but completely fail to fight back in any manner. And this is after they take a raft on a camping trip, with no gear, and show up at a campsite that is already assembled and completely stocked with food and clothes and the daughters headphones. Additionally, after their boat goes missing, they panic that they're stuck in the woods, but then the daughters boyfriend just shows up and they apparently never consider that they could just hike out of the woods like he did to get to them. Like I said, this movie sucks. A complete joke. Don't let your girlfriend talk you into watching it.\"\n",
    "\n",
    "Label: ``Negative``\n",
    "\n",
    "The dataset is provided by the HuggingFace ``datasets`` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-james",
   "metadata": {},
   "source": [
    "For demonstration purposes, let's filter this dataset down to 100 training samples and 100 test samples. The ``generate_dataset_activations`` function will then generate and cache a pickled set of activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def generate_dataset_activations(split, dataset, client):\n",
    "\n",
    "    print(\"Generating Activations: \" + split)\n",
    "\n",
    "    module_names = [\n",
    "        'decoder.layers.11.fc2'\n",
    "    ]\n",
    "\n",
    "    activations = []\n",
    "    BATCH_SIZE = 16\n",
    "    for batch in tqdm(batcher(dataset, BATCH_SIZE), total=int(len(dataset)/BATCH_SIZE)):\n",
    "        prompts = batch['text']\n",
    "        activations.append(client.get_activations(prompts, module_names))\n",
    "\n",
    "    parsed_activations = []\n",
    "    for batch in activations:\n",
    "        for prompt_activation in batch:\n",
    "            parsed_activations.append(prompt_activation['decoder.layers.11.fc2'])\n",
    "\n",
    "    cached_activations = {\n",
    "        'activations': parsed_activations,\n",
    "        'labels': dataset['label']\n",
    "    }\n",
    "\n",
    "    with open(split + '_activations_demo.pkl', 'wb') as handle:\n",
    "        pickle.dump(cached_activations, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_activations('train', small_train_dataset, client)\n",
    "generate_dataset_activations('test', small_test_dataset, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-madness",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "\n",
    "The cached activations can be loaded from disk to faciliate the fine-tuning of a classification model on the sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-slave",
   "metadata": {},
   "source": [
    "Let's define an Activation Dataset which will load our activations from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, activations_path):\n",
    "        self._load_activations(activations_path)\n",
    "        \n",
    "    def _load_activations(self, path):\n",
    "        with open(path, 'rb') as handle:\n",
    "            cached_activations = pickle.load(handle)\n",
    "        self.activations = cached_activations['activations']\n",
    "        self.labels = cached_activations['labels']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.activations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.activations[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-corpus",
   "metadata": {},
   "source": [
    "We will be performing classification on the last token of the sequence, common practive for autoregressive models (e.g. GPT-3). The following ``batch_last_token`` collate function will be passed into the dataloader to extract the last token activation from each sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_last_token(batch):\n",
    "    (x, y) = zip(*batch)\n",
    "    \n",
    "    x = torch.stack([seq[-1] for seq in x])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-corpus",
   "metadata": {},
   "source": [
    "And a MLP to perform the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(cfg['embedding_dim'], cfg['hidden_dim'], bias=False)\n",
    "        self.out = nn.Linear(cfg['hidden_dim'], cfg['label_dim'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.out(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ActivationDataset('./train_activations.pkl')\n",
    "test_dataset = ActivationDataset('./test_activations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=batch_last_token)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True, collate_fn=batch_last_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-dragon",
   "metadata": {},
   "source": [
    "We can now write a relatively simple script to train and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP({\n",
    "        \"embedding_dim\": 768,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"label_dim\": 2\n",
    "    })\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "pbar = tqdm(range(NUM_EPOCHS))\n",
    "for epoch_idx in pbar:\n",
    "\n",
    "    pbar.set_description(\"Epoch: %s\" % epoch_idx)\n",
    "    training_params = {\n",
    "        \"Train-Loss\": 0.0,\n",
    "        \"Test-Accuracy\": 0.0\n",
    "    }\n",
    "    pbar.set_postfix(training_params)\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "\n",
    "        activations, labels = batch\n",
    "        activations = activations.float().cuda()\n",
    "        labels = torch.tensor(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(activations)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_params[\"Train-Loss\"] = loss.detach().item()\n",
    "        pbar.set_postfix(training_params)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        for batch in test_dataloader:\n",
    "            activations, labels = batch\n",
    "            activations = activations.float().cuda()\n",
    "            labels = torch.tensor(labels).cuda()\n",
    "\n",
    "            logits = model(activations)\n",
    "            predictions.extend((logits.argmax(dim=1) == labels)) \n",
    "\n",
    "\n",
    "        accuracy = torch.stack(predictions).sum() / len(predictions)\n",
    "\n",
    "        training_params[\"Test-Accuracy\"] = accuracy.detach().item()\n",
    "        pbar.set_postfix(training_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-price",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have demonstrated a simple workflow for interfacing with remote models on the Vector cluster. Additionally, we have show how you can generate and cache activations for fine-tuning models offline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt-demo",
   "language": "python",
   "name": "opt-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
